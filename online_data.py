import requests
from bs4 import BeautifulSoup

# --- BACKUP DE URGENÈšÄ‚ (DacÄƒ totul picÄƒ la prezentare) ---
BACKUP_DB = {
    "mancity": 1, "realmadrid": 2, "liverpool": 3, "inter": 4, 
    "arsenal": 5, "barcelona": 6, "psg": 7, "bayern": 8,
    "fcsb": 100, "cfrcluj": 110, "craiova": 120, "rapid": 130
}

def get_online_elo(team_name):
    """
    Scraping 'Brute Force' pe clasamentul UEFA.
    CiteÈ™te orice rÃ¢nd din tabel, indiferent de cum e scris codul HTML.
    """
    # Link cÄƒtre clasamentul 2025 (stabil)
    url = "https://kassiesa.net/uefa/data/method5/trank2026.html"
    headers = {'User-Agent': 'Mozilla/5.0'}

    try:
        print(f"ğŸ“¡ Scraping pe: {url}...")
        response = requests.get(url, headers=headers, timeout=10)
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # --- SCHIMBARE MAJORÄ‚: LuÄƒm absolut TOATE rÃ¢ndurile din paginÄƒ ---
        # Nu mai cÄƒutÄƒm clase specifice care se pot schimba.
        rows = soup.find_all('tr')
        
        print(f"âœ… Conectat! Analizez {len(rows)} rÃ¢nduri de date...")

        # PregÄƒtim numele cÄƒutat
        clean_input = team_name.lower().replace(" ", "").strip()
        
        # Mapare Nume (Tu -> Site)
        mapping = {
            "mancity": "mancity",      
            "manchestercity": "mancity",
            "manchesterunited": "manutd",
            "realmadrid": "realmadrid",
            "barcelona": "barcelona",
            "barca": "barcelona",
            "fcsb": "fcsb",
            "steaua": "fcsb",
            "cfr": "cfrcluj",
            "cfrcluj": "cfrcluj",
            "rapid": "rapidbucuresti",
            "dinamo": "dinamobucuresti"
        }
        target = mapping.get(clean_input, clean_input)
        
        # CÄƒutÄƒm Ã®n fiecare rÃ¢nd
        for row in rows:
            # LuÄƒm tot textul din rÃ¢nd, eliminÄƒm spaÈ›iile È™i punctele
            # Ex: "1 Man City Eng 120.000" devine "1mancityeng120000"
            text = row.get_text().lower().replace(" ", "").replace(".", "").replace("\n", "")
            
            # VerificÄƒm dacÄƒ numele È›intÄƒ e acolo
            if target in text:
                # ÃncercÄƒm sÄƒ extragem numÄƒrul de la Ã®nceput (Rank-ul)
                try:
                    # GÄƒsim coloanele rÃ¢ndului
                    cols = row.find_all('td')
                    if cols and len(cols) > 0:
                        rank_text = cols[0].get_text().strip()
                        if rank_text.isdigit():
                            rank = int(rank_text)
                            print(f"ğŸ‰ GÄ‚SIT PE NET! {team_name} -> Locul {rank}")
                            return rank
                except:
                    continue # DacÄƒ dÄƒ eroare la un rÃ¢nd, trecem la urmÄƒtorul

        print("âš ï¸ Nu am gÄƒsit pe site, trec pe Backup...")
        
    except Exception as e:
        print(f"âš ï¸ Eroare conexiune ({e}). Trec pe Backup...")

    # --- PLAN B: BACKUP ---
    # DacÄƒ scraping-ul eÈ™ueazÄƒ sau nu gÄƒseÈ™te echipa, folosim lista localÄƒ
    if clean_input in BACKUP_DB:
        print(f"ğŸ“‚ Folosesc date interne: {clean_input} -> {BACKUP_DB[clean_input]}")
        return BACKUP_DB[clean_input]
    
    # DacÄƒ nici Ã®n backup nu e, returnÄƒm un rank mediu (50) ca sÄƒ nu crape
    return 50